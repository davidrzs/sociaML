{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sociaml.analysis import *\n",
    "from sociaml.preprocessing import *\n",
    "\n",
    "import glob\n",
    "import tqdm\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_folder = './videos/'\n",
    "audio_folder = './audios'\n",
    "json_folder = './transcriptions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all mp4 files in the folder\n",
    "files = glob.glob(pitch_folder + '*.mp4')\n",
    "\n",
    "# let us look at all files:\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in tqdm.tqdm(files):\n",
    "    \n",
    "    filename = Path(video).stem\n",
    "    audio_path = Path(audio_folder) / (filename + '.mp3')\n",
    "    json_path = Path(json_folder) / (filename + '.json')\n",
    "    \n",
    "    \n",
    "    transcriber = TranscriberAndDiarizer(device=torch.device(\"cuda\"),pyannote_api_key='PYANNOTE_KEY_HERE',merge_consecutive_speakers=True)\n",
    "    anonymizer = Anonymizer()\n",
    "    audio_extractor = AudioExtractor()\n",
    "\n",
    "\n",
    "    audio_extractor.process(video, audio_path=audio_path)\n",
    "    trs = transcriber.process(video)\n",
    "    trs = anonymizer.process(trs)\n",
    "\n",
    "\n",
    "    # now we save trs as json\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(trs.to_json(), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
