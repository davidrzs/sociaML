{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/david/Programming/sociaML/examples\n"
     ]
    }
   ],
   "source": [
    "from sociaml.analysis import *\n",
    "from sociaml.preprocessing import *\n",
    "\n",
    "import glob\n",
    "import tqdm\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = '../tests/test_assets/President_Obama_takes_the_Oath_of_Office_(HD).ogv.720p.vp9.webm'\n",
    "\n",
    "audio_file = \"../tests/test_assets/audio.mp3\"\n",
    "audio_extractor = AudioExtractor()\n",
    "audio, samplerate = audio_extractor.process(video, audio_path=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.1.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.1.2+cu121. Bad things might happen unless you revert torch to 1.x.\n",
      "Detected language: en (0.99) in first 30s of audio...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tempfile.NamedTemporaryFile(suffix='.mp3') as temp_mp3:\n",
    "    transcriber = TranscriberAndDiarizer(pyannote_api_key=os.getenv('PYANNOTE_API_KEY'),merge_consecutive_speakers=True)\n",
    "    anonymizer = Anonymizer()\n",
    "    trs = transcriber.process(video)\n",
    "    trs = anonymizer.process(trs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contribution(start=0.677, end=2.799, speaker='SPEAKER_01', transcript=' Please raise your right hand and repeat after me.')\n",
      "Contribution(start=2.819, end=37.599, speaker='SPEAKER_00', transcript='I, <PERSON>, do solemnly swear that I will faithfully execute the office of President of the United States.  and will, to the best of my ability, preserve, protect, and defend the Constitution of the United States. So help you God. Congratulations, Mr. President. Thank you, Mr. Chief Justice. Thank you so much. Thank you, sweetie.')\n",
      "Contribution(start=38.84, end=39.54, speaker='UNKNOWN', transcript='Thank you.')\n",
      "Contribution(start=41.76, end=45.982, speaker='SPEAKER_00', transcript='I did it. All right. Thank you, everybody.')\n"
     ]
    }
   ],
   "source": [
    "for contribution in trs.contributions:\n",
    "    print(contribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
